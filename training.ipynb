{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d6b804-e494-472b-ae1e-b5f8305bdc36",
      "metadata": {
        "id": "56d6b804-e494-472b-ae1e-b5f8305bdc36"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!mkdir -p /data/sets/nuimages  # Make the directory to store the nuImages dataset in.\n",
        "!wget https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz  # Download the nuImages mini split.\n",
        "!tar -xf nuimages-v1.0-mini.tgz -C /data/sets/nuimages  # Uncompress the nuImages mini split.\n",
        "!pip install lightning numpy nuscenes-devkit pillow torch\n",
        "\n",
        "!git clone https://github.com/GordonGustafson/semantic-segmentation.git\n",
        "%cd semantic-segmentation/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "O7_WBnxWVmwk"
      },
      "id": "O7_WBnxWVmwk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataloader import *\n",
        "from nuimages import NuImages\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "nuimages = NuImages(dataroot='/data/sets/nuimages', version='v1.0-mini', verbose=True, lazy=True)\n",
        "dataset = NuImagesDataset(nuimages)\n",
        "\n",
        "sem_seg_sample = dataset['0f37924ef2b54da7a233091d95311a38']\n",
        "\n",
        "fig, axs = plt.subplots(2)\n",
        "axs[0].imshow(sem_seg_sample.image, interpolation='nearest')\n",
        "axs[1].imshow(sem_seg_sample.segmentation_mask, interpolation='nearest')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mLVM4POj0HdA"
      },
      "id": "mLVM4POj0HdA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataloader import get_mini_dataloader, image_transform_to_dict_transform\n",
        "\n",
        "from torch import optim, nn\n",
        "import torchvision.transforms as T\n",
        "import lightning as L\n",
        "\n",
        "# TODO: figure out the correct value for this.\n",
        "# 31 is the largest value I've seen so far, but haven't looked very hard.\n",
        "NUM_CLASSES = 32\n",
        "\n",
        "\n",
        "# define the LightningModule\n",
        "class PixelWiseSegmentation(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images = batch[\"image\"]                             # shape = (N, C, H, W)\n",
        "        gt_segmentation_masks = batch[\"segmentation_mask\"]  # shape = (N, H, W)\n",
        "        predicted_segmentation_masks = self.model(images)\n",
        "        return nn.functional.cross_entropy(predicted_segmentation_masks, gt_segmentation_masks)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.AdamW(self.model.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "# init the model\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=NUM_CLASSES, kernel_size=1, padding=0, stride=1)\n",
        "model = PixelWiseSegmentation(conv)\n",
        "\n",
        "# setup data\n",
        "transform = image_transform_to_dict_transform(T.ToTensor())\n",
        "train_dataloader = get_mini_dataloader(batch_size=2, transform=transform)\n",
        "\n",
        "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
        "trainer = L.Trainer(limit_train_batches=100, max_epochs=1)\n",
        "trainer.fit(model=model, train_dataloaders=train_dataloader)\n"
      ],
      "metadata": {
        "id": "IQx56MV1U1as"
      },
      "id": "IQx56MV1U1as",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}